# -*- coding: utf-8 -*-
"""PMV_PPD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pFo2EcBqw7Phj-APCOZJbXhGwzC_xvW7
"""

import numpy as np
import pandas as pd
import time
from google.colab import drive
from keras.layers import LSTM
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Dropout
from sklearn.preprocessing import MinMaxScaler
import keras
from sklearn import datasets
from sklearn import metrics
from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

drive.mount('/content/gdrive')

df = pd.read_csv("/content/gdrive/MyDrive/PMV_PPD/db_measurements_v2.1.0.csv")

df.columns

considered = df[["ta","tr","vel","rh","met","clo"]]
predictors = df[['pmv', 'ppd', 'pmv_ce', 'ppd_ce']]
classifiers = df[["thermal_acceptability","thermal_preference","thermal_comfort"]]

df[["thermal_acceptability","thermal_preference","thermal_comfort"]]

df[['pmv', 'ppd', 'pmv_ce', 'ppd_ce']]

new_df = df[["ta","tr","vel","rh","met","clo",'pmv', 'ppd', 'pmv_ce', 'ppd_ce',"thermal_acceptability","thermal_preference","thermal_comfort"]]

new_df = new_df.dropna(axis=0)

new_df.columns

new_df.dtypes

new_df["thermal_acceptability"].value_counts()

new_df["thermal_acceptability"] = new_df["thermal_acceptability"].apply(lambda row : 1 if row=="acceptable" else 0)

new_df["thermal_preference"].value_counts()

new_df["thermal_comfort"].value_counts()

X = new_df[["ta","tr","vel","rh","met","clo"]]
y = new_df[["pmv"]]

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
sc_y = StandardScaler()
X = sc_X.fit_transform(X)
y = sc_y.fit_transform(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error,r2_score
regressor = SVR(kernel = 'rbf')
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)
mean_squared_error(y_pred,y_test)
r2_score(y_pred,y_test)

# save the model to disk
import pickle
filename = '/content/gdrive/MyDrive/PMV_PPD/models/pmv_model.sav'
pickle.dump(regressor, open(filename, 'wb'))

loaded_model = pickle.load(open(filename, 'rb'))
result = regressor.predict(X_test)
print(r2_score(result,y_test))

X1 = new_df[["ta","tr","vel","rh","met","clo"]]
y1 = new_df[["ppd"]]

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
sc_y = StandardScaler()
X1 = sc_X.fit_transform(X1)
y1 = sc_y.fit_transform(y1)

from sklearn.model_selection import train_test_split
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1,random_state=1)

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error,r2_score
regressor = SVR(kernel = 'rbf')
regressor.fit(X_train1, y_train1)
y_pred1 = regressor.predict(X_test1)
mean_squared_error(y_pred1,y_test1)
r2_score(y_pred1,y_test1)

# save the model to disk
import pickle
filename = '/content/gdrive/MyDrive/PMV_PPD/models/ppd_model.sav'
pickle.dump(regressor, open(filename, 'wb'))

loaded_model = pickle.load(open(filename, 'rb'))
result = regressor.predict(X_test1)
print(r2_score(result,y_test1))

"""# **UNSUPERVISED LEARNING FOR THESE ATTRIBUTES**"""

X2 = new_df[["ta","tr","vel","rh","met","clo","pmv","ppd"]]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_df_kmeans = scaler.fit_transform(X2)

from sklearn.cluster import KMeans
kmeans_model = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
clusters = kmeans_model.fit_predict(scaled_df_kmeans)

# save the model to disk
import pickle
filename = '/content/gdrive/MyDrive/PMV_PPD/models/unsup_kMeans_model.sav'
pickle.dump(kmeans_model, open(filename, 'wb'))

pd.DataFrame(clusters).value_counts()

X2

new_df.iloc[0]

cluster0 = []
cluster1 = []
cluster2 = []
cluster0 = {
            'ta': [0],
            'tr':[0],
            'vel':[0],
            'rh':[0], 
            'met':[0], 
            'clo':[0],
            'pmv':[0], 
            'ppd':[0], 
            'pmv_ce':[0],
            'ppd_ce':[0], 
            'thermal_acceptability':[0],
            'thermal_preference':[0], 
            'thermal_comfort':[0], 
}
cluster0 = pd.DataFrame(cluster0)


cluster1 = {
            'ta': [0],
            'tr':[0],
            'vel':[0],
            'rh':[0], 
            'met':[0], 
            'clo':[0],
            'pmv':[0], 
            'ppd':[0], 
            'pmv_ce':[0],
            'ppd_ce':[0], 
            'thermal_acceptability':[0],
            'thermal_preference':[0], 
            'thermal_comfort':[0], 
}
cluster1 = pd.DataFrame(cluster1)


cluster2 = {
            'ta': [0],
            'tr':[0],
            'vel':[0],
            'rh':[0], 
            'met':[0], 
            'clo':[0],
            'pmv':[0], 
            'ppd':[0], 
            'pmv_ce':[0],
            'ppd_ce':[0], 
            'thermal_acceptability':[0],
            'thermal_preference':[0], 
            'thermal_comfort':[0], 
}
cluster2 = pd.DataFrame(cluster2)



for i in range(0,len(new_df)):
  if(clusters[i]==0):
    cluster0 = cluster0.append(new_df.iloc[i])
  elif(clusters[i]==1):
    cluster1 = cluster1.append(new_df.iloc[i])
  else:
    cluster2 = cluster2.append(new_df.iloc[i])

cluster0.to_csv("/content/gdrive/MyDrive/PMV_PPD/semi_data/one.csv")
cluster1.to_csv("/content/gdrive/MyDrive/PMV_PPD/semi_data/two.csv")
cluster2.to_csv("/content/gdrive/MyDrive/PMV_PPD/semi_data/three.csv")

df

second = pd.read_csv("/content/gdrive/MyDrive/PMV_PPD/semi_data/two.csv")

second.dtypes

second["thermal_comfort"].value_counts()

second.corr()

second_df = second.drop(0,axis=0)
second_df = second.drop("Unnamed: 0",axis=1)

X = second_df.iloc[:,:10]
y = second_df["thermal_acceptability"]

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# create a logistic regression model
lr = LogisticRegression()

# fit the model with the training data
lr.fit(X_train, y_train)

# make predictions on the testing data
y_pred = lr.predict(X_test)

# evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# create a Random Forest classifier with 100 trees
rf = RandomForestClassifier(n_estimators=100)

# fit the model with the training data
rf.fit(X_train, y_train)

# make predictions on the testing data
y_pred = rf.predict(X_test)

# evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# save the model to disk
import pickle
filename = '/content/gdrive/MyDrive/PMV_PPD/models/thermal_acc_model.sav'
pickle.dump(rf, open(filename, 'wb'))

X1 = second_df.iloc[:,:10]
y1 = second_df["thermal_comfort"]

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=42)

# create a logistic regression model
lr1 = LogisticRegression()

# fit the model with the training data
lr1.fit(X_train, y_train)

# make predictions on the testing data
y_pred = lr1.predict(X_test)

# evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# save the model to disk
import pickle
filename = '/content/gdrive/MyDrive/PMV_PPD/models/thermal_comfort_model.sav'
pickle.dump(lr1, open(filename, 'wb'))

